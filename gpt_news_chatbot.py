import os
import pandas as pd
import streamlit as st
from langchain_openai import ChatOpenAI

# 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = st.secrets["OPENAI_API_KEY"]

# 2. ì—‘ì…€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
excel_path = "newsclip_db_updated.xlsx"
df = pd.read_excel(excel_path)
df.columns = df.columns.str.strip()  # ê³µë°± ì œê±°

# ì»¬ëŸ¼ í™•ì¸ (ë””ë²„ê¹…ìš©, ë¬¸ì œ í•´ê²° í›„ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
# st.write(df.columns.tolist())

# 3. ë‰´ìŠ¤ ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ contextë¡œ í†µí•©
docs = []
for _, row in df.iterrows():
    if isinstance(row.get("ë‰´ìŠ¤ìš”ì•½"), str) and row["ë‰´ìŠ¤ìš”ì•½"].strip():
        date = str(row.get("ë‚ ì§œ", ""))[:10]
        title = row.get("í•´ë“œë¼ì¸", "")
        summary = row["ë‰´ìŠ¤ìš”ì•½"].strip()
        docs.append(f"[{date}] {title} : {summary}")

context_text = "\n".join(docs)

# 4. GPT ëª¨ë¸ ì¤€ë¹„
llm = ChatOpenAI(
    model_name="gpt-3.5-turbo",
    temperature=0.3,
    openai_api_key=api_key
)

# 5. Streamlit ì¸í„°í˜ì´ìŠ¤
st.set_page_config(page_title="ë‰´ìŠ¤ ìš”ì•½ GPT ì±—ë´‡", layout="wide")
st.title("ğŸ“° ë‰´ìŠ¤ ìš”ì•½ ê¸°ë°˜ ê²½ì˜ì§„ ì§ˆì˜ì‘ë‹µ GPT")

question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: 4ì›” êµìœ¡ì •ì±… ìš”ì•½í•´ì¤˜")

if question:
    with st.spinner("GPTê°€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
        prompt = f"""
        ì•„ë˜ëŠ” ë‰´ìŠ¤ ìš”ì•½ ë°ì´í„°ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ëŠ” ë‚´ìš©ì„ ì •ë¦¬í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”. 
        íŠ¹íˆ ë¹„ìƒêµìœ¡ì´ ì¤‘ì‹¬ì´ ë˜ëŠ” ê¸°ì‚¬ê°€ ìˆë‹¤ë©´ ê·¸ ë‚´ìš©ì„ ê°•ì¡°í•´ ì£¼ì„¸ìš”.

        ì§ˆë¬¸: {question}

        ë‰´ìŠ¤ ìš”ì•½:
        {context_text}
        """
        try:
            response = llm.predict(prompt)
            st.success("ë‹µë³€ ê²°ê³¼:")
            st.markdown(response)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
